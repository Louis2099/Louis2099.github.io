<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Autonomous Object Tracking Robot | Jiaxing/Louis Li </title> <meta name="author" content="Jiaxing/Louis Li"> <meta name="description" content="A ROS2-based autonomous robot using YOLOv8 and Isaac ROS for real-time detection and tracking of 80 COCO dataset objects with stereoscopic depth perception."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.jpg?c79371331d24b810be043b47f8e3fd60"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://louis2099.github.io/projects/2_project/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jiaxing/Louis</span> Li </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Autonomous Object Tracking Robot</h1> <p class="post-description">A ROS2-based autonomous robot using YOLOv8 and Isaac ROS for real-time detection and tracking of 80 COCO dataset objects with stereoscopic depth perception.</p> </header> <article> <h2 id="overview">Overview</h2> <p>This project was developed as the final assignment for <strong>Autonomous Robotics I</strong> (Spring 2025) at Carnegie Mellon University, taught by <a href="https://z4ziad.github.io/2025-05-13-auto_robo_update_2/" rel="external nofollow noopener" target="_blank">Prof. Ziad Youssfi</a>. The goal was to build an autonomous mobile robot capable of finding and tracking any user-specified object from the 80 classes in the COCO dataset using state-of-the-art computer vision and robotics frameworks.</p> <p>The robot successfully integrates deep learning-based object detection, ROS 2 (Robot Operating System 2) for distributed control, and NVIDIA’s Isaac ROS accelerated libraries for real-time inference on edge computing hardware.</p> <h2 id="system-architecture">System Architecture</h2> <h3 id="hardware-platform">Hardware Platform</h3> <ul> <li> <strong>Mobile Base</strong>: Waveshare JetBot chassis with differential drive</li> <li> <strong>Computing</strong>: NVIDIA Jetson Orin Nano (GPU-accelerated edge AI computer)</li> <li> <strong>Vision</strong>: Intel RealSense D435i camera with RGB and stereoscopic depth sensing</li> <li> <strong>Power</strong>: Onboard battery system for autonomous operation</li> </ul> <h3 id="software-stack">Software Stack</h3> <ul> <li> <strong>Operating System</strong>: Ubuntu 20.04 with ROS 2 Foxy</li> <li> <strong>Object Detection</strong>: YOLOv8 (You Only Look Once) trained on COCO dataset</li> <li> <strong>Acceleration</strong>: NVIDIA Isaac ROS for GPU-optimized computer vision pipelines</li> <li> <strong>Control Framework</strong>: ROS 2 Action Server/Client architecture for asynchronous task management</li> </ul> <h2 id="implementation">Implementation</h2> <p>The system was implemented using a distributed ROS 2 architecture:</p> <h3 id="1-perception-pipeline">1. <strong>Perception Pipeline</strong> </h3> <ul> <li>Real-time video streaming from Intel RealSense camera</li> <li>Hardware-accelerated YOLOv8 inference using Isaac ROS DNN nodes</li> <li>Detection of 80 object classes (person, car, bottle, teddy bear, etc.) with confidence scores</li> <li>Depth estimation for 3D localization of detected objects</li> </ul> <h3 id="2-ros-2-action-server">2. <strong>ROS 2 Action Server</strong> </h3> <ul> <li>Implemented a custom action server for object search and tracking tasks</li> <li>Accepts client requests specifying target object class</li> <li>Provides feedback on search progress (scanning, object detected, tracking)</li> <li>Returns success/failure status with final object position</li> </ul> <h3 id="3-ros-2-action-client">3. <strong>ROS 2 Action Client</strong> </h3> <ul> <li>Command interface allowing users to specify target objects</li> <li>Handles action goal submission and result processing</li> <li>Manages state transitions between searching, tracking, and idle modes</li> </ul> <h3 id="4-motion-control">4. <strong>Motion Control</strong> </h3> <ul> <li>Differential drive controller for base navigation</li> <li>PID-based visual servoing to center target in camera frame</li> <li>Adaptive speed control based on object distance and confidence</li> <li>Obstacle avoidance using depth information</li> </ul> <h2 id="performance-and-results">Performance and Results</h2> <p>The robot successfully demonstrated autonomous object finding and tracking capabilities across multiple object classes:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_img/project2/Finding%20the%20Teddy%20Bear_short%20-%20SD%20480p-480.webp 480w,/assets/img/project_img/project2/Finding%20the%20Teddy%20Bear_short%20-%20SD%20480p-800.webp 800w,/assets/img/project_img/project2/Finding%20the%20Teddy%20Bear_short%20-%20SD%20480p-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_img/project2/Finding%20the%20Teddy%20Bear_short%20-%20SD%20480p.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Teddy Bear Tracking" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_img/project2/Finding%20an%20orange_short%20-%20SD%20480p-480.webp 480w,/assets/img/project_img/project2/Finding%20an%20orange_short%20-%20SD%20480p-800.webp 800w,/assets/img/project_img/project2/Finding%20an%20orange_short%20-%20SD%20480p-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_img/project2/Finding%20an%20orange_short%20-%20SD%20480p.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Orange Detection" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Real-time demonstrations: (Left) Successfully finding and tracking a teddy bear; (Right) Detecting and tracking an orange among other objects. </div> <h3 id="key-achievements">Key Achievements:</h3> <ul> <li> <strong>Detection Accuracy</strong>: Successfully detected target objects with &gt;90% confidence in varied lighting conditions</li> <li> <strong>Tracking Stability</strong>: Maintained continuous visual tracking while navigating toward targets</li> <li> <strong>Real-time Performance</strong>: Achieved 15-20 FPS inference rate on Jetson Orin Nano</li> <li> <strong>Multi-object Handling</strong>: Correctly distinguished between different object classes in cluttered scenes</li> <li> <strong>Depth Integration</strong>: Used stereoscopic depth for distance estimation and approach control</li> </ul> <h3 id="technical-highlights">Technical Highlights:</h3> <ul> <li> <strong>Robust Object Recognition</strong>: YOLOv8’s single-shot detection enabled fast, accurate identification without manual feature engineering</li> <li> <strong>GPU Acceleration</strong>: Isaac ROS reduced inference latency by ~3x compared to CPU-only implementation</li> <li> <strong>Asynchronous Control</strong>: ROS 2 action framework allowed non-blocking task execution with real-time feedback</li> <li> <strong>Modular Architecture</strong>: Clean separation between perception, planning, and control enabled rapid debugging and iteration</li> </ul> <h2 id="challenges-and-solutions">Challenges and Solutions</h2> <h3 id="hardware-logistics">Hardware Logistics</h3> <p>The project faced significant logistical challenges with late delivery of the robot base and supply constraints on the Jetson Orin Nano (NVIDIA’s price reduction led to widespread unavailability). Despite having only a few weeks for hardware testing, the team successfully integrated all components and achieved the demonstration objectives.</p> <h3 id="software-integration">Software Integration</h3> <p>Integrating Isaac ROS with custom ROS 2 nodes required careful attention to message types, timing, and GPU memory management. The solution involved using ROS 2’s component composition for efficient zero-copy message passing and configuring Isaac ROS parameters for optimal Jetson performance.</p> <h2 id="future-improvements">Future Improvements</h2> <p>Potential enhancements identified for future iterations:</p> <ul> <li>Integration with <strong>Isaac Sim</strong> for software-in-the-loop testing before hardware deployment</li> <li>Implementation of <strong>Visual SLAM</strong> for autonomous mapping and localization</li> <li> <strong>Path planning algorithms</strong> (e.g., A*, RRT) for navigation in complex environments</li> <li> <strong>SMACC2 state machines</strong> for more structured behavior management</li> <li>Multi-object tracking for simultaneous detection of multiple targets</li> </ul> <h2 id="course-context">Course Context</h2> <p>This project synthesized knowledge from three main course modules:</p> <ol> <li> <strong>Deep Learning Fundamentals</strong>: Understanding CNNs, loss functions, and training pipelines</li> <li> <strong>ROS 2 Ecosystem</strong>: Publishers, subscribers, services, actions, and distributed systems</li> <li> <strong>Isaac ROS Integration</strong>: GPU-accelerated perception for real-time robotics applications</li> </ol> <p>The hands-on nature of the project made abstract ML concepts tangible and demonstrated the practical challenges of deploying AI on resource-constrained robotics platforms. Special thanks to Prof. Ziad Youssfi and the teaching assistants for their support throughout the semester!</p> </article> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"Louis2099/Louis2099.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jiaxing/Louis Li. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>